{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0hbD79ObqgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8516161c-5bae-4c8b-8eaa-6183c2e252ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!randam --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvDmWipoKiR",
        "outputId": "31af125d-6eb4-416e-f117-85f8d16c8c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: randam: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "9uRf_DwOvlhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 歌詞とコードのデータのロード\n",
        "file_path = '/content/drive/My Drive/lyrics_and_chords_separated.csv'\n",
        "#file_path = '/content/drive/My Drive/perfect_song_lyrics_chords.csv'\n",
        "#data = pd.read_csv(file_path, encoding='utf-8')\n",
        "data = pd.read_csv(file_path, encoding='cp932')"
      ],
      "metadata": {
        "id": "fZY0aFj7xC-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CSVファイルのStatusが\"1\"の行だけを抽出（歌詞とコードが揃っている行）\n",
        "#filtered_data = data[data['Status'] == 1].dropna(subset=['Lyrics', 'Chords']).reset_index(drop=True)\n",
        "#filtered_data = data\n",
        "# データをDataFrameに変換\n",
        "#df = pd.DataFrame(filtered_data, columns=['URL', 'Lyrics', 'Chords'])\n",
        "#df = pd.DataFrame(filtered_data, columns=['Lyrics', 'Chords'])\n",
        "# CSVファイルに保存\n",
        "#f.to_csv('/content/drive/My Drive/lyrics_and_chords_separated4.csv', index=False, encoding='utf-8')\n",
        "# 歌詞とコードのペアを確認\n",
        "data.head()\n",
        "#filtered_data.head()\n",
        "#file_path = '/content/drive/My Drive/lyrics_and_chords_separated4.csv'"
      ],
      "metadata": {
        "id": "zcq6MFqImUus",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "8ea9ec18-6213-4fe9-8a91-52a1a92b4f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 URL  \\\n",
              "0  https://tabs.ultimate-guitar.com/tab/ed-sheera...   \n",
              "1  https://tabs.ultimate-guitar.com/tab/jeff-buck...   \n",
              "2  https://tabs.ultimate-guitar.com/tab/elvis-pre...   \n",
              "3  https://tabs.ultimate-guitar.com/tab/john-lege...   \n",
              "4  https://tabs.ultimate-guitar.com/tab/jason-mra...   \n",
              "\n",
              "                                              Lyrics  \\\n",
              "0  I found a love for me Darling, just dive right...   \n",
              "1  I heard there was a secret chord That David pl...   \n",
              "2  Wise men say, only fools rush in But I can't h...   \n",
              "3  What would I do without your smart mouth Drawi...   \n",
              "4  Well, you done done me in; you bet I felt it I...   \n",
              "\n",
              "                                              Chords  \n",
              "0  G G Em C D G Em C D G Em C G D G Em C D Em C G...  \n",
              "1  C Am C Am F G C G C F G Am F G E7 Am F Am F C ...  \n",
              "2  C G Am F C G C C Em Am F C G F G Am F C G C C ...  \n",
              "3  Em C G D Em Cmaj7 G D Em C G D Em Cmaj7 G D Em...  \n",
              "4  G D Em C B G D A E G D Em C G D Em C G D Em C ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f43df5f6-400d-4800-a195-b8aca42eae6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>Chords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/ed-sheera...</td>\n",
              "      <td>I found a love for me Darling, just dive right...</td>\n",
              "      <td>G G Em C D G Em C D G Em C G D G Em C D Em C G...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/jeff-buck...</td>\n",
              "      <td>I heard there was a secret chord That David pl...</td>\n",
              "      <td>C Am C Am F G C G C F G Am F G E7 Am F Am F C ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/elvis-pre...</td>\n",
              "      <td>Wise men say, only fools rush in But I can't h...</td>\n",
              "      <td>C G Am F C G C C Em Am F C G F G Am F C G C C ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/john-lege...</td>\n",
              "      <td>What would I do without your smart mouth Drawi...</td>\n",
              "      <td>Em C G D Em Cmaj7 G D Em C G D Em Cmaj7 G D Em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tabs.ultimate-guitar.com/tab/jason-mra...</td>\n",
              "      <td>Well, you done done me in; you bet I felt it I...</td>\n",
              "      <td>G D Em C B G D A E G D Em C G D Em C G D Em C ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f43df5f6-400d-4800-a195-b8aca42eae6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f43df5f6-400d-4800-a195-b8aca42eae6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f43df5f6-400d-4800-a195-b8aca42eae6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fea882f2-3fdb-4be0-8e6f-4b6905892d57\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fea882f2-3fdb-4be0-8e6f-4b6905892d57')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fea882f2-3fdb-4be0-8e6f-4b6905892d57 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"#file_path = '/content/drive/My Drive/lyrics_and_chords_separated4\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"URL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://tabs.ultimate-guitar.com/tab/jeff-buckley/hallelujah-chords-198052\",\n          \"https://tabs.ultimate-guitar.com/tab/jason-mraz/im-yours-chords-373896\",\n          \"https://tabs.ultimate-guitar.com/tab/elvis-presley/cant-help-falling-in-love-chords-1086983\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lyrics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I heard there was a secret chord That David played and it pleased the Lord But you don't really care for music, do you? Well it goes like this the fourth, the fifth The minor fall and the major lift The baffled king composing hallelujah Well, your faith was strong but you needed proof You saw her bathing on the roof Her beauty and the moonlight overthrew you She tied you to her kitchen chair She broke your throne and she cut your hair And from your lips she drew the hallelujah Baby, I've been here before I've seen this room and I've walked this floor I used to live alone before I knew you I've seen your flag on the marble arch But love is not a victory march It's a cold and it's a broken hallelujah Well, there was a time when you let me know What's really going on below But now you never show that to me do you But remember when I moved in you And the holy dove was moving too And every breath we drew was hallelujah Well, maybe there's a God above But all I've ever learned from love Was how to shoot somebody who outdrew you It's not a cry that you hear at night It's not somebody who's seen the light It's a cold and it's a broken hallelujah Halleluuuuuuujah\",\n          \"Well, you done done me in; you bet I felt it I tried to be chill but you're so hot that I melted I fell right through the cracks Now I'm tryin' to get back Before the cool done run out, I'll be givin' it my bestest and nothin's gonna stop me but divine intervention I reckon it's again my turn To win some or learn some But I won't hesitate No more, no more It cannot wait; I'm yours Well, open up your mind and see like me Open up your plans and damn you're free Look into your heart and you'll find love, love, love, love Listen to the music of the moment, people dance and sing, we're just one big family And it's our Godforsaken right to be loved, loved, loved, loved, loved So I won't hesitate No more, no more It cannot wait, I'm sure There's no need to complicate Our time is short This is our fate, I'm yours Doo do do doo doo do, doo do doo do doo do Do you want to come on, scooch on over closer, dear And I will nibble your ear I've been spending way too long checking my tongue in the mirror And bending over backwards just to try to see it clearer But my breath fogged up the glass And so I drew a new face and I laughed I guess what I'll be saying is there ain't no better reason To rid yourself of vanities and just go with the seasons It's what we aim to do Our name is our virtue But I won't hesitate No more, no more It cannot wait; I'm yours Well, open up your mind and see like me Open up your plans and damn you're free Look into your heart and you'll find that the sky is yours So please don't, please don't, please don't There's no need to complicate 'Cause our time is short This oh, this oh, this is our fate I'm yours Brrbammm, dabammmday Tdu, du, tdu, du, tdu, dudu, duu, dudu Oh, I'm yours Oh, I'm yours Ohohohoh, whoaohohoh Baby, do believe I'm yours You best believe, you best believe I'm yours\",\n          \"Wise men say, only fools rush in But I can't help falling in love with you Shall I stay, would it be a sin? If I can't help falling in love with you Like a river flows surely to the sea Darling so it goes Some things are meant to be Take my hand, take my whole life too For I can't help falling in love with you Like a river flows surely to the sea Darling so it goes Some things are meant to be Take my hand, take my whole life too For I can't help falling in love with you For I can't help falling in love with you Alternate: Open m It has been suggested that or might be a good substitute for This version: comvideossearch?qelvis+presley+cant+help+ falling+in+love+video&viewdetail&midFFDABAAFFDABAA&FORMVIRE Set\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"C Am C Am F G C G C F G Am F G E7 Am F Am F C G C Am C Am C Am C Am F G C G C F G Am F G E7 Am F Am F C G C Am C Am C Am C Am F G C G C F G Am F G E7 Am F Am F C G C Am C Am C Am C Am F G C G C F G Am F G E7 Am F Am F C G C Am C Am C Am C Am F G C G C F G Am F G E7 Am F Am F C G C F Am F C G C F Am F C G C Am F G C\",\n          \"G D Em C B G D A E G D Em C G D Em C G D Em C G D Em C G D Em C G D Em C A7 G D Dsus4 Em C G D Em C G D Em D C A7 G Bm Em D C A7 G D Em C G D Em C G D Dsus4 Em C G D Em C G D Dsus4 Em C A7 C G D Em C G D Em C\",\n          \"C G Am F C G C C Em Am F C G F G Am F C G C C Em Am F C G F G Am F C G C Em B7 Em B7 Em B7 Em A7 Dm G C Em Am F C G F G Am F C G C Em B7 Em B7 Em B7 Em A7 Dm G C Em Am F C G F G Am F C G C C F G Am F C G C C D Em F#m Am Bm F G G A B7 C#7 A7 B7 Dm Em Dm Dm7 F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "text_pairs = []\n",
        "#with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
        "with open(file_path, newline='', encoding='cp932') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    next(reader)  # ヘッダーをスキップ\n",
        "    for row in reader:\n",
        "        if len(row) >= 3:\n",
        "        #if len(row) >= 2:\n",
        "            eng = row[1].strip()  # 歌詞\n",
        "            #eng = row[0].strip()  # 歌詞\n",
        "            chords = row[2].strip()  # コード進行\n",
        "            #chords = row[1].strip()  # コード進行\n",
        "            chords = \"[start] \" + chords + \" [end]\"  # 開始・終了トークンを追加\n",
        "            text_pairs.append((eng, chords))\n"
      ],
      "metadata": {
        "id": "AEJJLyJ3w7CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHivNMArxwlf",
        "outputId": "fb32e062-8548-474c-fde8-bcd27610b6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Never mind, I'll find someone like you\", '[start] A E F#m [end]')\n",
            "(\"And you're married now\", '[start] F#m D [end]')\n",
            "(\"Come up to meet you, tell you I'm sorry, you don't know how lovely you are\", '[start] Bm7 G Gadd9 D Dsus2 [end]')\n",
            "('Wait for me to come home', '[start] G D [end]')\n",
            "(\"When I was six years old I broke my leg And I was running from my brother and his friends And tasted the sweet perfume of the mountain grass as I rolled down I was younger then, take me back to when I Found my heart and broke it here Made friends and lost them through the years And I've not seen the roaring fields in so long, I know I've grown But I can't wait to go home Asus I'm on my way, driving at ninety Asus Down those country lanes singing to Tiny Dancer Asus And I miss the way you make me feel and it's real Asus When we watched the sunset over the castle on the hill Fifteen years old and smoking handrolled cigarettes Running from the law through the backfields and getting drunk with my friends Had my first kiss on a Friday night, I don't reckon I did it Right, I was younger then, take me back to when we found Weekend jobs and when we got paid We'd buy cheap spirits and drink them straight Me and my friends have not thrown up in so long, oh how we've grown But I can't wait to go home Asus I'm on my way, driving at ninety Asus Down those country lanes singing to Tiny Dancer Asus And I miss the way you make me feel and it's real Asus We watched the sunset over the castle on the hill Asus Over the castle on the hill Asus Over the castle on the hill Asus Asus One friend left to sell clothes, one works down by the coast Asus One had two kids but lives alone, one's brother overdosed Asus One's already on his second wife, one's just barely getting by but Asus These people raised me and III, can't wait to go home Asus And I'm on my way, I still remember Asus These old country lanes when we did not know the answers Asus And I miss the way you make me feel and it's real Asus We watched the sunset over the castle on the hill Asus Over the castle on the hill Asus Over the castle on the hill comwatch?vYtbJciBcE and : 遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・> > > > > > > > > > > > : Asus xxxxxx 遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶翫・遶雁・繝ｻ strumming pattern > accented note x dead note\", '[start] D G D Bm D F A D F G G D G D Bm Bm A D D D F G Bm A D D F G Bm A D D F G Bm A D D F G Bm A G A D G G A D G G A D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D D F G Bm A D D F G Bm A D D F G Bm A D D F G Bm A G A D G G A D G G A D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D F G Bm Bm G D Bm G D Bm G D Bm G D Bm G D D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D F G Bm D D D F G Bm A B G D A E D D F G Bm Bm7 B G D A E [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot9jVQ3dtSeq",
        "outputId": "7ec4f20f-8728-4868-c833-32d9489079f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1037 total pairs\n",
            "727 training pairs\n",
            "155 validation pairs\n",
            "155 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for _ in range(6):\n",
        "    print((test_pairs[i]))\n",
        "    i = i +1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfxE7BGIt1iw",
        "outputId": "a00a2be6-1d56-4a8e-d61f-585c77576dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"By now you should've somehow\", '[start] Em7 G G [end]')\n",
            "('Well me, I fall in love with you every single day', '[start] G Dm G Am [end]')\n",
            "('And if the night is burning', '[start] Am7 Am7 Em [end]')\n",
            "('and still those voices are calling from far away', '[start] F F C [end]')\n",
            "('Raise a glass of wine for the last time', '[start] C Em G D Am7 [end]')\n",
            "('Darling, just dive right in, and follow my lead', '[start] Em C C D [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "strip_chars = strip_chars.replace(\"/\", \"\")#この行がないと\"/\"が出力されない\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf_strings.lower(input_string)\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")#区切り文字を削除する\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "chords_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")"
      ],
      "metadata": {
        "id": "1NYtArhfCILc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_chords_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "chords_vectorization.adapt(train_chords_texts)"
      ],
      "metadata": {
        "id": "SfUCZqZPRwHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(eng, chords):\n",
        "    eng = eng_vectorization(eng)\n",
        "    chords = chords_vectorization(chords)\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": chords[:, :-1],\n",
        "        },\n",
        "        chords[:, 1:],\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, chords_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    chords_texts = list(chords_texts)\n",
        "    dataset = tf_data.data.Dataset.from_tensor_slices((eng_texts, chords_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n"
      ],
      "metadata": {
        "id": "CHr1zcqEEgtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "bju9N9sqR1Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ORmCl6IqD6",
        "outputId": "cfcd21e6-69c1-437f-cda5-f66577df66bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer\n",
        "from keras.saving import register_keras_serializable\n",
        "import keras\n",
        "from keras import layers\n",
        "import keras.ops as ops\n",
        "\n",
        "@register_keras_serializable(package=\"Custom\")\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "@register_keras_serializable(package=\"Custom\")\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "@register_keras_serializable(package=\"Custom\")\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ],
      "metadata": {
        "id": "7NWitKlWNpXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "id": "jpk144F-Pddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40  # This should be at least 40 for convergence\n",
        "             # accuracyが低かったらepochs数を増やす\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q0YykfEiQfPv",
        "outputId": "0681209e-c978-4d6f-9a0d-f4659cf61118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │     \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 5s/step - accuracy: 0.4063 - loss: 7.5427 - val_accuracy: 0.5216 - val_loss: 4.1906\n",
            "Epoch 2/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.5709 - loss: 3.4200 - val_accuracy: 0.5224 - val_loss: 2.4588\n",
            "Epoch 3/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 5s/step - accuracy: 0.5835 - loss: 2.1545 - val_accuracy: 0.5877 - val_loss: 1.8198\n",
            "Epoch 4/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.6277 - loss: 1.6536 - val_accuracy: 0.6067 - val_loss: 1.6252\n",
            "Epoch 5/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.6298 - loss: 1.5050 - val_accuracy: 0.6112 - val_loss: 1.5269\n",
            "Epoch 6/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.6578 - loss: 1.3354 - val_accuracy: 0.6220 - val_loss: 1.4579\n",
            "Epoch 7/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.6472 - loss: 1.3791 - val_accuracy: 0.6078 - val_loss: 1.4802\n",
            "Epoch 8/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 5s/step - accuracy: 0.6466 - loss: 1.3263 - val_accuracy: 0.5937 - val_loss: 1.4570\n",
            "Epoch 9/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.6249 - loss: 1.3583 - val_accuracy: 0.6231 - val_loss: 1.3993\n",
            "Epoch 10/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5s/step - accuracy: 0.6671 - loss: 1.2143 - val_accuracy: 0.6187 - val_loss: 1.3915\n",
            "Epoch 11/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.6538 - loss: 1.2750 - val_accuracy: 0.6392 - val_loss: 1.3191\n",
            "Epoch 12/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 5s/step - accuracy: 0.6658 - loss: 1.1807 - val_accuracy: 0.6347 - val_loss: 1.3228\n",
            "Epoch 13/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - accuracy: 0.6729 - loss: 1.1203 - val_accuracy: 0.6399 - val_loss: 1.2962\n",
            "Epoch 14/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5s/step - accuracy: 0.6488 - loss: 1.2273 - val_accuracy: 0.6522 - val_loss: 1.2496\n",
            "Epoch 15/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.6972 - loss: 1.0284 - val_accuracy: 0.6493 - val_loss: 1.2579\n",
            "Epoch 16/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.6991 - loss: 1.0593 - val_accuracy: 0.6567 - val_loss: 1.2137\n",
            "Epoch 17/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.6968 - loss: 1.0230 - val_accuracy: 0.6556 - val_loss: 1.2326\n",
            "Epoch 18/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.7089 - loss: 0.9839 - val_accuracy: 0.6578 - val_loss: 1.2257\n",
            "Epoch 19/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.7203 - loss: 0.9509 - val_accuracy: 0.6724 - val_loss: 1.1416\n",
            "Epoch 20/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5s/step - accuracy: 0.7231 - loss: 0.9171 - val_accuracy: 0.6724 - val_loss: 1.1270\n",
            "Epoch 21/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 5s/step - accuracy: 0.7423 - loss: 0.8552 - val_accuracy: 0.6836 - val_loss: 1.1077\n",
            "Epoch 22/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.7573 - loss: 0.8096 - val_accuracy: 0.6866 - val_loss: 1.0481\n",
            "Epoch 23/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 5s/step - accuracy: 0.7609 - loss: 0.7778 - val_accuracy: 0.7168 - val_loss: 1.0123\n",
            "Epoch 24/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 5s/step - accuracy: 0.8009 - loss: 0.6882 - val_accuracy: 0.7254 - val_loss: 1.0045\n",
            "Epoch 25/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.8231 - loss: 0.6113 - val_accuracy: 0.7705 - val_loss: 0.8502\n",
            "Epoch 26/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.8675 - loss: 0.4737 - val_accuracy: 0.8034 - val_loss: 0.8029\n",
            "Epoch 27/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5s/step - accuracy: 0.8940 - loss: 0.3973 - val_accuracy: 0.8239 - val_loss: 0.6853\n",
            "Epoch 28/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.9110 - loss: 0.3373 - val_accuracy: 0.8582 - val_loss: 0.5649\n",
            "Epoch 29/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 5s/step - accuracy: 0.9071 - loss: 0.3671 - val_accuracy: 0.9004 - val_loss: 0.4343\n",
            "Epoch 30/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.9633 - loss: 0.1663 - val_accuracy: 0.9302 - val_loss: 0.3084\n",
            "Epoch 31/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5s/step - accuracy: 0.9798 - loss: 0.1006 - val_accuracy: 0.9451 - val_loss: 0.2503\n",
            "Epoch 32/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.9842 - loss: 0.0860 - val_accuracy: 0.9552 - val_loss: 0.2200\n",
            "Epoch 33/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.9884 - loss: 0.0583 - val_accuracy: 0.9709 - val_loss: 0.1673\n",
            "Epoch 34/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.9940 - loss: 0.0382 - val_accuracy: 0.9724 - val_loss: 0.1566\n",
            "Epoch 35/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 5s/step - accuracy: 0.9949 - loss: 0.0360 - val_accuracy: 0.9705 - val_loss: 0.1590\n",
            "Epoch 36/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.9946 - loss: 0.0278 - val_accuracy: 0.9724 - val_loss: 0.1614\n",
            "Epoch 37/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 5s/step - accuracy: 0.9795 - loss: 0.0883 - val_accuracy: 0.9724 - val_loss: 0.1493\n",
            "Epoch 38/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 5s/step - accuracy: 0.9966 - loss: 0.0231 - val_accuracy: 0.9750 - val_loss: 0.1395\n",
            "Epoch 39/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 5s/step - accuracy: 0.9984 - loss: 0.0191 - val_accuracy: 0.9791 - val_loss: 0.1260\n",
            "Epoch 40/40\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 5s/step - accuracy: 0.9991 - loss: 0.0117 - val_accuracy: 0.9795 - val_loss: 0.1261\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e45786a6b90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルを保存\n",
        "# 保存先ファイルパスを指定（.keras形式）\n",
        "#transformer.save('/content/drive/My Drive/saved_transformer_model.keras')"
      ],
      "metadata": {
        "id": "1cvk46HJkTdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.models import load_model\n",
        "\n",
        "# モデルをロード\n",
        "#loaded_model = load_model('/content/drive/My Drive/saved_transformer_model.keras', custom_objects={\"PositionalEmbedding\": PositionalEmbedding})\n",
        "\n",
        "# ロードされたモデルの確認\n",
        "#loaded_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "5Oc94mmKkW9t",
        "outputId": "322b7a63-48c7-491e-a9cc-e03e31df1fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'positional_embedding', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'positional_embedding_1', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'transformer_decoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │     \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,920,434\u001b[0m (152.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,920,434</span> (152.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,960,218\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,218</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##コード生成の例(実験では使用していない)"
      ],
      "metadata": {
        "id": "8mJS--ohl0GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "chords_vocab = chords_vectorization.get_vocabulary()\n",
        "chords_index_lookup = dict(zip(range(len(chords_vocab)), chords_vocab))\n",
        "max_decoded_sentence_length = 4#出力するコードの最大の数\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = chords_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = chords_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(1):\n",
        "    #input_sentence = random.choice(test_eng_texts)\n",
        "    input_sentence = (\"I caught a cold because I kept turning the air conditioning on.\")\n",
        "    translated = decode_sequence(input_sentence)"
      ],
      "metadata": {
        "id": "qE9DmkcAwQqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print((input_sentence))\n",
        "print((translated))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1EjOr7XW-GA",
        "outputId": "5fcd503e-428a-44e7-8833-1166f59c6077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I caught a cold because I kept turning the air conditioning on.\n",
            "[start] em d g [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**英文のコード生成(実験3)**"
      ],
      "metadata": {
        "id": "WyjJl-r9vKXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chords_vocab = chords_vectorization.get_vocabulary()\n",
        "chords_index_lookup = dict(zip(range(len(chords_vocab)), chords_vocab))\n",
        "max_decoded_sentence_length = 4#出力するコードの最大の数\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = chords_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = chords_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence.replace(\"[start] \", \"\").replace(\" [end]\", \"\")\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "i=0\n",
        "file_path = '/content/drive/My Drive/English.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "output_path = '/content/drive/My Drive/English_with_Chords.csv'\n",
        "for _ in range(100):\n",
        "    #input_sentence = random.choice(test_eng_texts)\n",
        "    input_sentence = (data['Lyrics'][i])\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print((input_sentence))\n",
        "    print((translated))\n",
        "    data.at[i, 'Chords'] = translated\n",
        "    data.to_csv(output_path, index=False)\n",
        "    i=i+1\n",
        "\n",
        "print(f\"コード進行を生成し、結果を保存しました: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqS-h77a6Yw6",
        "outputId": "8fe0ce86-ca0f-4d61-d162-af470285b8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I caught a cold because I kept turning the air conditioning on. \n",
            "em/b bm ab a7sus4\n",
            "I did not watch the video completely. \n",
            "em/b e7/g e7 d\n",
            "I have a sore throat after discussing passionately about the topic. \n",
            "em/b bm g7 dm\n",
            "A smartphone does not function when the touch ID is not put correctly. \n",
            "em/b a7sus4 a7sus4 d\n",
            "You have to put in the password every time. \n",
            "em/b em gadd9\n",
            "I was exhausted after having club practice after school. \n",
            "asus4 fm dsus4 c9\n",
            "I'd like to have some good ramen tonight.\n",
            "e7 em d7 gmaj7\n",
            "I overslept, so I missed the first period.\n",
            "em/b b7 g d7\n",
            "Would you come and join our club festival?\n",
            "c e7 f cmaj7\n",
            "You might be nervous at first, but I hope you will get accustomed to it sooner or later.\n",
            "em/b am7 e c/e\n",
            "The teacher's lessons are always dull, so I am sleepy during class. \n",
            "em/b f gmaj7 d7\n",
            "I have so much homework to write reports to do that I would not complete them.\n",
            "em/b b7 b7 b7\n",
            "I made many friends when I attended the welcome party. \n",
            "em/b e7 em7 dsus4\n",
            "Which classes should I take to get the credit more accessible? \n",
            "em/b cadd9 g a/g\n",
            "The first half of the class video was easy to understand, but the second half was not. \n",
            "em/b e7 b d\n",
            "I could not buy the textbook for my class because they were sold out in the campus bookstore. \n",
            "em/b e7 b d\n",
            "I didn't have time to study because I was busy with my part-time job. \n",
            "em/b cadd9\n",
            "If you don't get credit for this class, you will not be graduated. \n",
            "c fmaj7 a7sus4 d\n",
            "I'm going to participate in the company's internship during the summer vacation, \n",
            "em/b em gadd9\n",
            "I'm so tired that I don't feel like studying.\n",
            "b7 b7 em7 g\n",
            "I could have done better in the final examination of the subject. \n",
            "em/b cadd9 b7 e\n",
            "Can you introduce your friend to me? \n",
            "c f e e9/d\n",
            "Can you get me something cold from the vending machine?\n",
            "c dsus2 a g\n",
            "I fell asleep in English class, and the teacher woke me up.\n",
            "em/b f\n",
            "I can't finish studying because there are so many subjects to look at for the final exam.\n",
            "fm6 b c2\n",
            "I looked at my smartphone during the class, but the teacher did not recognize it.\n",
            "em/b f am d7\n",
            "If you have no idea to solve this math problem, you'd better go to the tutors to ask a question \n",
            "c f dsus2 cadd9\n",
            "He is too busy with club activities to study.\n",
            "a7 eb f cm7\n",
            "Have you finished making the presentation slides for the class?\n",
            "c f d7 d\n",
            "Could you check my presentation slides? I want to get your advice. \n",
            "c a am e9/d\n",
            "As it rains heavily, I'll ask my mother to pick me up at the university entrance. \n",
            "a em7 gmaj7 c/e\n",
            "I always feel so sleepy during the lesson in that teacher's class. \n",
            "em/b cmaj7 b7 b7\n",
            "We're looking forward to attending the summer seminar with our classmates. \n",
            "em/b cmaj7 em d\n",
            "Today's classes were enjoyable because we participated in an interesting experiment. \n",
            "em/b fm7 e e9/d\n",
            "Could you tell me how to make the presentation slides?\n",
            "c fm/c a gadd9\n",
            "Come to join us for the welcome party after the class. \n",
            "em cmaj7 am7 d7\n",
            "Can you go to the classroom first and give me a seat?\n",
            "c gsus4 em d\n",
            "Here are the handouts distributed in the last class. \n",
            "d/a d asus4 \n",
            "I am tired of playing games on my smartphone.\n",
            "em/b d b g\n",
            "I finally got the credit for the class after doing the assignments.\n",
            "em/b cadd9 d d7\n",
            "Some of my friends commute to school from far distance.\n",
            "b am e e9/d\n",
            "You will gain high abilities if you attend the online class regularly.\n",
            "d/f em7 e7/g g\n",
            "Today in class, the teacher told an interesting story and I had a lot of fun.\n",
            "[end]\n",
            "I'm so tired from studying for the test.\n",
            "b7 b7 cm dsus4\n",
            "My university is far from the station, and we must go by bus.\n",
            "em/b a7 eb a7sus4\n",
            "The buses to our university do not run fluently and are always crowded. \n",
            "em/b em cadd9 c/e\n",
            "It's really tough to go to the university by bus. \n",
            "em/b cmaj7 em f\n",
            "I wish there were more buses for the university. \n",
            "em/b e7 gmaj7 fm\n",
            "How long does it take from the station to the university by bus? \n",
            "em/b fm/c gadd9 a/g\n",
            "It's crazy to walk from the station to the university.\n",
            "fm em gadd9 gadd9\n",
            "Some students go to university by bicycle. \n",
            "em/b f em f\n",
            "If I came by bicycle, I'm sure I would be tired before class and fall asleep.\n",
            "g eb cadd9 c/e\n",
            "He always boasts that he rides his bike to school.  \n",
            "em/b cadd9 em7 a7sus4\n",
            "I really envy you going to school by bike.\n",
            "em/b f c dm\n",
            "I will save money to buy a motorcycle.\n",
            "d/f g eb em\n",
            "I'm looking for a good part-time job for students.\n",
            "em/b d7 bm a/g\n",
            "Is there any good part-time job that wouldn't interfere with your studies at university? \n",
            "em/b cmaj7 dm7 a7sus4\n",
            "The professor in my laboratory introduced me to a good job.\n",
            "em/b\n",
            "I plan to give a presentation on this research in the upcoming workshop. \n",
            "em/b em gadd9 bm\n",
            "My professor told me that this research theme is difficult.\n",
            "em/b cadd9 a em7\n",
            "I need to find more materials to continue this research.\n",
            "g em gm e9/d\n",
            "I spend a long time in the lab when I do experiments.\n",
            "em/b bm ab em/b\n",
            "There are many things to learn before conduction experiments.\n",
            "a/g e7/g a7sus4 em\n",
            "I've learned that there are merits of utilizing deep learning systems.\n",
            "em/b em7 dsus4 asus4\n",
            "Deep learning systems can be used in various ways. \n",
            "em/b f c7 am7\n",
            "Now I understand the concept of algorism.\n",
            "g eb d em/b\n",
            "In the future, I want to work for a manufacturing company.\n",
            "d b7 g d7\n",
            "Have you ever attended internship programs for companies?\n",
            "c gmaj7 d7 gmaj7\n",
            "A career adviser advised me to attend the job fair.\n",
            "em/b f d7 a\n",
            "The representatives of local companies will attend the job fair.\n",
            "em/b b c2 em/b\n",
            "You must make a reservation to attend the job fair.\n",
            "em/b b7 bm ab\n",
            "Now that I'm a junior, I must consider getting a job. \n",
            "em7 bb bm ab\n",
            "After graduating, I want to engage in game-producing companies. \n",
            "em/b g bsus4 em\n",
            "Have you ever heard about esports?\n",
            "c dsus2 f7 e7\n",
            "Professional game players are making a living through competitive gaming.\n",
            "em/b e7 d/a\n",
            "If I became a professional gamer, I could enjoy my life.\n",
            "g e9 bm ab\n",
            "Reservation is required to attend the popular event. \n",
            "a7 eb em d7\n",
            "As I'm worried about finding a job, I will talk to my teacher. \n",
            "bb f gadd9 g\n",
            "I recommend going to the tutoring center if you need help studying. \n",
            "em/b cm7 em d\n",
            "I found out how to solve the problem when I asked my teacher.\n",
            "em/b ab gadd9 em\n",
            "What do you think is the best way to make friends?\n",
            "em/b c dm a7\n",
            "I think he will be my lifelong friend. \n",
            "em/b cadd9 d/f am7\n",
            "I will never forget these fond memories spent on my campus.\n",
            "d/f d6 d7 gmaj7\n",
            "My professor always told me not to give up even some difficulties happen.\n",
            "em/b d/f cm a\n",
            "I'm happy to make friends with students from different departments. \n",
            "em/b em bm7 e\n",
            "There are a few international students at this university. \n",
            "d/a bm ab dsus4\n",
            "In seminars, everyone should participate actively in discussions. \n",
            "em/b fm/c gadd9 gadd9\n",
            "It is a lot of fun to attend other students' research presentations. \n",
            "a7 bm ab b\n",
            "If you are asked a question in your presentation, you should answer honestly.\n",
            "c gmaj7 fm bm\n",
            "His approach to the research is very informative.\n",
            "em/b em d em/b\n",
            "Although creating game characters was time-consuming, I found it to be fun. \n",
            "em/b d am7 asus4\n",
            "The professor suggests that, by utilizing algorithms, this process could be easier. \n",
            "em/b cadd9 em7 em7\n",
            "I would like to have more advice on creating the presentation slides. \n",
            "em/b e7 em d7\n",
            "Could you tell me what this error message suggests?\n",
            "c fm/c a a7sus4\n",
            "This app always gives us error messages. \n",
            "em/b d/f a g/b\n",
            "I can't imagine life without a smartphone.\n",
            "fm6 eb f a7sus4\n",
            "It took a lot of work to prepare presentation assignments in class.\n",
            "em/b bm ab b\n",
            "When I showed him my research outline, he gave me much advice.\n",
            "g cadd9 b7 am\n",
            "My classmate's presentation on that theme inspired me.\n",
            "em/b cadd9 cadd9 em7\n",
            "I have the ambition to become a scientist who works globally.\n",
            "em/b d am7 em\n",
            "コード進行を生成し、結果を保存しました: /content/drive/My Drive/English_with_Chords4.csv\n"
          ]
        }
      ]
    }
  ]
}